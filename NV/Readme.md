# Nevada Legislative Data Pipeline

A multi-stage Python toolkit to scrape, parse, and combine Nevada legislative data (bills, summaries, statuses, sponsors, history, votes) into unified JSON outputs. 

---

## ğŸš€ Overview

This repo automates the end-to-end conversion of raw NV legislative webpages into four final JSON datasets:

1. **bill_metadata.json**  
2. **sponsors.json**  
3. **bill_history.json**  
4. **votes.json**

It is organized into discrete steps:
1. **Index â†’ Base Data**  
2. **Base Data â†’ Metadata**  
3. **Sponsor Search & Sponsor Parsing**  
4. **History Parsing**  
     Where A -, S -, G -, P - prefixes indicate Assmebly, Senate, Govenor, and Previous action's prefix is likely correct, but it was ambiguous
5. **Votes Parsing**  
6. **Combine All Outputs**
7. **Query any State Bill**


Each step lives in `conversion_functions/<step_name>.py` and can be run independently or all at once via the top-level launcher.

---

## âš™ï¸ Steps

- Python 3.8+  
- Install dependencies with a virtual environment:
  `python -m venv .venv`
  `.venv\Scripts\activate`
  `pip install -r requirements.txt`
- Run start.py with:
  `python code\start.py`
  This will take about 15 minutes, with intermediate print outs, then subsequent queries will be instant.
  I have already ran this for you to generate the intermediate JSONs, but if the conversion scripts are updated, then you must rerun start.py 
- Query any bill with:
  # Query by state, session, and bill id
  `python code\query.py --state NV --session 70th1999 --state_bill_id AB444`

  # Query by UUID only and dump to file
  `python code\query.py --uuid NV70th1999AB444`

  With the resulting JSON of the query in `output/query/NV70th1999AB444.json`




.
â”œâ”€â”€ code/
â”‚   â””â”€â”€ start.py                # Step 1: Runs all the scripts end-to-end
â”‚   â”œâ”€â”€ index_to_json.py        # Step 2: Scrape bill index â†’ JSON
â”‚   â”œâ”€â”€ basedata.py             # Step 3: Normalize base JSON
â”‚   â”œâ”€â”€ metadata.py             # Step 4: Summaries, statuses, AN ACT titles
â”‚   â”œâ”€â”€ sponsorsearch.py        # Step 5a: Scrape primary/cosponsor lists  
â”‚   â”œâ”€â”€ sponsors.py             # Step 6b: Adds Sponsors and Cosponsors to their respective bills
â”‚   â”œâ”€â”€ history.py              # Step 7: Parse bill history actions, see above for prefix details
â”‚   â”œâ”€â”€ votes.py                # Step 8: Parse roll-call votes
â”‚   â””â”€â”€ combiner.py             # Step 9: Stitch everything into 4 big JSONs
â”‚   â””â”€â”€ query.py                # Step 10: Query any bill using either UUID or state, state_bill_id, and session as arguments
â”‚
â”œâ”€â”€ intermediate/               # â† Default working area
â”‚   â”œâ”€â”€ index_to_json/          # raw JSONs outputs from the bill index sites
â”‚   â”œâ”€â”€ basedata/               # normalized base data that every bill inherits and reads
â”‚   â”œâ”€â”€ metadata/               # bill_metadata_*.json
â”‚   â”œâ”€â”€ sponsors/               # sponsor_search + sponsors outputs
â”‚   â”œâ”€â”€ history/                # parsed history JSONs
â”‚   â””â”€â”€ votes/                  # parsed vote JSONs
â”‚
â”œâ”€â”€ output/                     # â† Final combined JSONs
â”‚   â”œâ”€â”€ bill_metadata.json
â”‚   â”œâ”€â”€ sponsors.json
â”‚   â”œâ”€â”€ bill_history.json
â”‚   â”œâ”€â”€ votes.json
â”‚   â””â”€â”€ query/                  # â† Final output of Bills you queried, returned as JSONs
â”‚       â””â”€â”€ 
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

